---
- name: Reify etcd variables for cluster configuration
  # Needed to access defaults variables through hostvars
  set_fact:
    etcd_member_name: "{{ etcd_member_name }}"
    etcd_peer_url: "{{ etcd_peer_url }}"
    etcd_events_peer_url: "{{ etcd_events_peer_url }}"

- name: Configure | Check if etcd cluster is healthy
  shell: "set -o pipefail && {{ bin_dir }}/etcdctl endpoint --cluster status && {{ bin_dir }}/etcdctl endpoint --cluster health  2>&1 | grep -v 'Error: unhealthy cluster' >/dev/null"
  args:
    executable: /bin/bash
  register: etcd_cluster_is_healthy
  failed_when: false
  changed_when: false
  check_mode: false
  run_once: true
  when:
    - etcd_cluster_setup
  tags:
    - facts
  environment:
    ETCDCTL_API: "3"
    ETCDCTL_CERT: "{{ etcd_cert_dir }}/admin-{{ inventory_hostname }}.pem"
    ETCDCTL_KEY: "{{ etcd_cert_dir }}/admin-{{ inventory_hostname }}-key.pem"
    ETCDCTL_CACERT: "{{ etcd_cert_dir }}/ca.pem"
    ETCDCTL_ENDPOINTS: "{{ etcd_access_addresses }}"

- name: Configure | Check if etcd-events cluster is healthy
  shell: "set -o pipefail && {{ bin_dir }}/etcdctl endpoint --cluster status && {{ bin_dir }}/etcdctl endpoint --cluster health  2>&1 | grep -v 'Error: unhealthy cluster' >/dev/null"
  args:
    executable: /bin/bash
  register: etcd_events_cluster_is_healthy
  failed_when: false
  changed_when: false
  check_mode: false
  run_once: true
  when:
    - etcd_events_cluster_setup
  tags:
    - facts
  environment:
    ETCDCTL_API: "3"
    ETCDCTL_CERT: "{{ etcd_cert_dir }}/admin-{{ inventory_hostname }}.pem"
    ETCDCTL_KEY: "{{ etcd_cert_dir }}/admin-{{ inventory_hostname }}-key.pem"
    ETCDCTL_CACERT: "{{ etcd_cert_dir }}/ca.pem"
    ETCDCTL_ENDPOINTS: "{{ etcd_events_access_addresses }}"

- name: Configure | Refresh etcd config
  import_tasks: refresh_config.yml

- name: Configure | Copy etcd.service systemd file
  template:
    src: "etcd-{{ etcd_deployment_type }}.service.j2"
    dest: /etc/systemd/system/etcd.service
    backup: true
    mode: "0644"
    # FIXME: check that systemd version >= 250 (factory-reset.target was introduced in that release)
    # Remove once we drop support for systemd < 250
    validate: "sh -c '[ -f /usr/bin/systemd/system/factory-reset.target ] || exit 0 && systemd-analyze verify %s:etcd-{{ etcd_deployment_type }}.service'"
  when:
    - etcd_cluster_setup

- name: Configure | Copy etcd-events.service systemd file
  template:
    src: "etcd-events-{{ etcd_deployment_type }}.service.j2"
    dest: /etc/systemd/system/etcd-events.service
    backup: true
    mode: "0644"
    validate: "sh -c '[ -f /usr/bin/systemd/system/factory-reset.target ] || exit 0 && systemd-analyze verify %s:etcd-events-{{ etcd_deployment_type }}.service'"
    # FIXME: check that systemd version >= 250 (factory-reset.target was introduced in that release)
    # Remove once we drop support for systemd < 250
  when:
    - etcd_events_cluster_setup

- name: Configure | reload systemd
  systemd_service:
    daemon_reload: true
  when: ('etcd' in group_names)

# when scaling new etcd will fail to start
- name: Configure | Ensure etcd is running
  service:
    name: etcd
    state: started
    enabled: true
  ignore_errors: "{{ etcd_cluster_is_healthy.rc == 0 }}"  # noqa ignore-errors
  when:
    - etcd_cluster_setup

# when scaling new etcd will fail to start
- name: Configure | Ensure etcd-events is running
  service:
    name: etcd-events
    state: started
    enabled: true
  ignore_errors: "{{ etcd_events_cluster_is_healthy.rc != 0 }}"  # noqa ignore-errors
  when:
    - etcd_events_cluster_setup

- name: Configure | Wait for etcd cluster to be healthy
  shell: "set -o pipefail && {{ bin_dir }}/etcdctl endpoint --cluster status && {{ bin_dir }}/etcdctl endpoint --cluster health 2>&1 | grep -v 'Error: unhealthy cluster' >/dev/null"
  args:
    executable: /bin/bash
  register: etcd_cluster_is_healthy
  until: etcd_cluster_is_healthy.rc == 0
  retries: "{{ etcd_retries }}"
  delay: "{{ retry_stagger | random + 3 }}"
  changed_when: false
  check_mode: false
  run_once: true
  when:
    - etcd_cluster_setup
  tags:
    - facts
  environment:
    ETCDCTL_API: "3"
    ETCDCTL_CERT: "{{ etcd_cert_dir }}/admin-{{ inventory_hostname }}.pem"
    ETCDCTL_KEY: "{{ etcd_cert_dir }}/admin-{{ inventory_hostname }}-key.pem"
    ETCDCTL_CACERT: "{{ etcd_cert_dir }}/ca.pem"
    ETCDCTL_ENDPOINTS: "{{ etcd_access_addresses }}"

- name: Configure | Wait for etcd-events cluster to be healthy
  shell: "set -o pipefail && {{ bin_dir }}/etcdctl endpoint --cluster status && {{ bin_dir }}/etcdctl endpoint --cluster health 2>&1 | grep -v 'Error: unhealthy cluster' >/dev/null"
  args:
    executable: /bin/bash
  register: etcd_events_cluster_is_healthy
  until: etcd_events_cluster_is_healthy.rc == 0
  retries: "{{ etcd_retries }}"
  delay: "{{ retry_stagger | random + 3 }}"
  changed_when: false
  check_mode: false
  run_once: true
  when:
    - etcd_events_cluster_setup
  tags:
    - facts
  environment:
    ETCDCTL_API: "3"
    ETCDCTL_CERT: "{{ etcd_cert_dir }}/admin-{{ inventory_hostname }}.pem"
    ETCDCTL_KEY: "{{ etcd_cert_dir }}/admin-{{ inventory_hostname }}-key.pem"
    ETCDCTL_CACERT: "{{ etcd_cert_dir }}/ca.pem"
    ETCDCTL_ENDPOINTS: "{{ etcd_events_access_addresses }}"

- name: Configure | List existing members in etcd cluster
  environment:
    ETCDCTL_API: "3"
    ETCDCTL_CERT: "{{ etcd_cert_dir }}/admin-{{ inventory_hostname }}.pem"
    ETCDCTL_KEY: "{{ etcd_cert_dir }}/admin-{{ inventory_hostname }}-key.pem"
    ETCDCTL_CACERT: "{{ etcd_cert_dir }}/ca.pem"
    ETCDCTL_ENDPOINTS: "{{ item.endpoints }}"
  command: "{{ bin_dir }}/etcdctl member list -w json"
  run_once: true
  delegate_to:
  register: etcd_members_in_cluster
  when: item.when
  loop:
    - cluster: main
      endpoints: "{{ etcd_access_addresses }}"
      when: "{{ etcd_cluster_setup }}"
    - cluster: events
      endpoints: "{{ etcd_events_access_addresses }}"
      when: "{{ etcd_events_cluster_setup }}"
  loop_control:
    label: item.cluster
  failed_when:
    - etcd_members_in_cluster is failed
    - ('connection refused') not in etcd_members_in_cluster.stderr # Don't fail on cluster creation
  changed_when: false
  check_mode: false
  tags:
    - facts

- name: Configure | Join member(s) to etcd cluster one at a time
  vars:
    etcd_member_names_to_hosts: "{{
    groups['etcd'] | map('extract', hostvars, 'etcd_member_name') |
    zip(groups['etcd']) |
    community.general.dict
  }}"
    # invert hostvars to map etcd_member_name to inventory_hostname
  block:
    - name: Configure | Join member(s) to etcd cluster one at a time | Main
      include_tasks:
        file: join_etcd_member.yml
        apply:
          vars:
            etcd_hosts: "{{ (current_members | map('extract', etcd_member_names_to_hosts)) + item }}"
      vars:
        current_members: "{{ (etcd_members_in_cluster.results[0].stdout | from_json).members | map(attribute='name') }}"
      with_items: "{{ (etcd_member_names_to_hosts | ansible.utils.remove_keys(target=current_members)).values() }}"
      # reject etcd hosts which are already in cluster
      when:
        - inventory_hostname == item
        - etcd_cluster_setup
        - etcd_cluster_is_healthy.rc == 0

    - name: Configure | Join member(s) to etcd cluster one at a time | Events
      include_tasks:
        file: join_etcd-events_member.yml
        apply:
          vars:
            etcd_hosts: "{{ (current_members | map('extract', etcd_member_names_to_hosts)) + item }}"
      vars:
        current_members: "{{ (etcd_members_in_cluster.results[1].stdout | from_json).members | map(attribute='name') }}"
      with_items: "{{ (etcd_member_names_to_hosts | ansible.utils.remove_keys(target=current_members)).values() }}"
      when:
        - inventory_hostname == item
        - etcd_events_cluster_setup
        - etcd_events_cluster_is_healthy.rc == 0
